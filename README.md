# Chinese-Word-Vectors
中文词向量
项目链接1：https://github.com/Embedding/Chinese-Word-Vectors
    该库包含经过数十种用各领域语料（百度百科、维基百科、人民日报 1947-2017、知乎、微博、文学、金融、古汉语等）训练的词向量，涵盖各领域，且包含多种训练设置。项目使用不同表征（稀疏和密集）、上下文特征（单词、n-gram、字符等）以及语料库训练的中文词向量（嵌入）。除了密集单词向量（以 SGNS 训练），该项目还提供了稀疏向量（以 PPMI 训练）。

项目链接2：https://ai.tencent.com/ailab/nlp/embedding.html
    总体来讲，腾讯AI实验室此次公开的中文词向量数据集包含800多万中文词汇，其中每个词对应一个200维的向量。训练词向量的语料来自腾讯新闻和天天快报的新闻语料，以及自行抓取的互联网网页和小说语料。腾讯AI Lab采用自研的Directional Skip-Gram (DSG)算法作为词向量的训练算法。
